* Write a manual of assumption we make about the videos in order to track everything
* Distinguish between debug/develop/release runs:
	- different default level of output
	- debug doesn't use multiprocessing to keep error messages clean
	- different logging behavior (log to file for release run!)
	- different error behavior (use some catch all try/except and log the error instead of failing in release run)
	- this could be implemented via helper functions in mousetracking.simple that configure python + parameters
* Determine absolute times by checking when the lights go on
* Get precise cage dimensions:
	- Do line scans at border in all directions and determine cage edge
	- Calculate length scale from cage dimension
	- Think about getting a more precise estimate of the cage
	- Get the width from the sand profile fits.
	- Get the height by doing a whole width line scan and determine the edge
* Define units for frames and pixel using pint (for proper output)
* Maybe we can get away with just using GrabCut for finding burrows?
	- Change explored area to never decay but just accumulate pixels at every frame
	- We can then get an idea of the explored area by requiring that a pixel has to be visited > 100 times
		This allows us to remove noise
	- Explored area can then be used in the GrabCut algorithm as potential foreground		
	- Think about redetermining centerlines of elongated burrows that have not been fitted in pass 2
* Add mechanism for conveniently defining parameters for single runs
* Gather more statistics about why certain parts of the algorithm failed
* Handle burrows with two entrances (e.g. video 14)
* Change parameters of output ffmpeg to produce useable videos, even when process was killed


Performance improvements:
-------------------------
* Make sure that images and masks are not copied to often (rather use internal cache structures, which should be faster)
	- Do operations in place as often as possible
* Generally cache all kernels for morphological operations, since these are costly to make
* Performance is limited by reading the video using ffmpeg (which is capped at about 50 fps)


Low priority enhancements:
--------------------------
* Apparently, sometimes the light flickers and a frame becomes unusably bright.
	- Get an example video to see how we could circumvent this problem in our code
	- One idea is to just drop these frames and assume that not much happens during this time
	- it seems we circumvent these problems by having a maximum for the number of moving objects  
