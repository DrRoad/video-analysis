* Write a manual of assumption we make about the videos in order to track everything
* Build collection of extracts from movies which are hard to analyze (use this for semi-automatic testing)
	- Write script to be able to easily extract problematic parts of the video and save them in a separate file 
* Distinguish between debug/develop/release runs:
	- different default level of output
	- debug doesn't use multiprocessing to keep error messages clean
	- different logging behavior (log to file for release run!)
	- different error behavior (use some catch all try/except and log the error instead of failing in release run)
	- this could be implemented via helper functions in mousetracking.simple that configure python + parameters
* When fitting burrows, set currently moving parts to sky color in background model and do the fitting on this image
* Simplify bulky burrows by removing trying to remove points and checking whether the area changes significantly
* Determine absolute times by checking when the lights go on


Performance improvements:
-------------------------
* Make sure that images and masks are not copied to often (rather use internal cache structures, which should be faster)
* Generally cache all kernels for morphological operations, since these are costly to make
* There are problems when ffmpeg can't encode the output videos fast enough:
	 - Presumably, the ffmpeg pipe gets full and the whole process just stops
* Calculate the Jacobian for the fitting explicitly (feasible for the sand profile)
* Loading the data from HDF is very slow - think about better format for collecting the data
	- maybe we could just be smarter about loading the relevant amount of data
	- a lazy loader and writer should be implemented
	- we could achieve this by subclassing Data and instantiate this for the right branches
	- this would require an observer class taking care of the mapping and how to store/read data 
* Writing the data is also slow since everything is rewritten every time


Low priority enhancements:
--------------------------
* Apparently, sometimes the light flickers and a frame becomes unusably bright.
	- Get an example video to see how we could circumvent this problem in our code
	- One idea is to just drop these frames and assume that not much happens during this time
* There is a memory leak somewhere. If the FirstPass object is deleted not all memory is released.
	- This should not pose any problems, since we usually only do one scan and then end the whole process
* Ground fitting could use some "active snake" ideas (http://en.wikipedia.org/wiki/Active_contour_model)
	- Alternatively, Speed up sand profile fitting by having a library of profiles with certain angles and just matching these
	around the point of interest (move along perpendicular line, until overlap is maximal)
* Extend the ground profile till the edge of the cage
	- this should automatically allow us to track the burrows close to the edge
* Look into the possibility of writing a VideoFFMPEG class, which directly uses ffmpeg to read a video
	- This will give us more flexibility in reading videos (also with more control over parameters)
	- see https://github.com/Zulko/moviepy/blob/master/moviepy/video/io/ffmpeg_reader.py
	- This should also allow us to read the video in a separate process/thread, thus speeding up the
		processing
	- This is also important to synchronize the video for the first and second pass, which currently
		does not work
	- Here, we might wanna introduce the distinction between VideoStreamBase and VideoBase, with the
		difference that the first one can only be iterated over, while the second allows for random access
* Write Query class, which can be used to query a complete data set to return useful data (like burrow length over time)
* Load the videos of a VideoStack one-by-one, only when they are actually needed
