* Write a manual of assumption we make about the videos in order to track everything
* Build collection of extracts from movies which are hard to analyze (use this for semi-automatic testing)
	- Write script to be able to easily extract problematic parts of the video and save them in a separate file 
* Distinguish between debug/develop/release runs:
	- different default level of output
	- debug doesn't use multiprocessing to keep error messages clean
	- different logging behavior (log to file for release run!)
	- different error behavior (use some catch all try/except and log the error instead of failing in release run)
	- this could be implemented via helper functions in mousetracking.simple that configure python + parameters
* When fitting burrows, set currently moving parts to sky color in background model and do the fitting on this image
* Simplify bulky burrows by trying to remove points and checking whether the area changes significantly
* Determine absolute times by checking when the lights go on
* Think about introducing a flag indicating whether we are sure we know where the mouse is (by considering its movement)
	- this could be used to reject moving objects that are certainly not a mouse
* Get precise cage dimensions:
	- Do line scans at border in all directions and determine cage edge
	- Calculate length scale from cage dimension
	- Think about getting a more precise estimate of the cage
	- Get the width from the sand profile fits.
	- Get the height by doing a whole width line scan and determine the edge
* Define units for frames and pixel using pint (for proper output)
* Find more reliable ground model
* Test burrow flood fill model (for bulky burrows?!)

Performance improvements:
-------------------------
* Make sure that images and masks are not copied to often (rather use internal cache structures, which should be faster)
	- Do operations in place as often as possible
* Generally cache all kernels for morphological operations, since these are costly to make
* Calculate the Jacobian for the fitting explicitly (feasible for the sand profile)
* Threaded reading of videos (get next frame in separate thread and store it for access)
	http://stackoverflow.com/questions/375427/non-blocking-read-on-a-subprocess-pipe-in-python
	http://stefaanlippens.net/python-asynchronous-subprocess-pipe-reading
	http://code.activestate.com/recipes/576759-subprocess-with-async-io-pipes-class/


Low priority enhancements:
--------------------------
* Apparently, sometimes the light flickers and a frame becomes unusably bright.
	- Get an example video to see how we could circumvent this problem in our code
	- One idea is to just drop these frames and assume that not much happens during this time
* There is a memory leak somewhere. If the FirstPass object is deleted not all memory is released.
	- This should not pose any problems, since we usually only do one scan and then end the whole process
* Ground fitting could use some "active snake" ideas (http://en.wikipedia.org/wiki/Active_contour_model)
	- Alternatively, Speed up sand profile fitting by having a library of profiles with certain angles and just matching these
	around the point of interest (move along perpendicular line, until overlap is maximal)
