* Read video in separate threads, because they are IO bound (and do not need the GIL)
* Find sand line and the burrow shape
	-  This might best be done on the background model (although it is blurred)
* We might want to rename the composer to DebugVideo, since this might be a narrow use case        
* A better solution would be to refactor the class such that there is a Debugger/Observer class 
and a general VideoComposer class
* Make mouse finding more robust, by keeping a score of how confident we are that we know where the mouse is
	- this score degrades over time, when we don't get a positional update
	- if the score drops below a threshold, we should consider looking for the mouse anywhere in the video
	- this should be done by using _find_mouse_in_binary_image
* Produce a color movie, which allows for better annotation
* Store meta information of video somewhere (especially date taken)
* Store mouse position and sand profile only for those time points where we actually have data. We then have
to store the frame index as well
* Write a manual of assumption we make about the videos in order to track everything